--- core.c	2024-08-16 22:35:16.000000000 +0700
+++ "core (Copy).c"	2020-01-01 11:40:00.000000000 +0700
@@ -29,7 +29,6 @@
 #include <linux/random.h>
 #include <linux/slab.h>
 #include <linux/of.h>
-#include <uapi/linux/sched/types.h>
 
 #include <linux/mmc/card.h>
 #include <linux/mmc/host.h>
@@ -42,7 +41,6 @@
 
 #include "core.h"
 #include "card.h"
-#include "queue.h"
 #include "bus.h"
 #include "host.h"
 #include "sdio_bus.h"
@@ -51,7 +49,12 @@
 #include "mmc_ops.h"
 #include "sd_ops.h"
 #include "sdio_ops.h"
-#include "mtk_mmc_block.h"
+
+#ifdef CONFIG_MMC_SUPPORT_STLOG
+#include <linux/fslog.h>
+#else
+#define ST_LOG(fmt, ...)
+#endif
 
 /* The max erase timeout, used when host->max_busy_timeout isn't specified */
 #define MMC_ERASE_TIMEOUT_MS	(60 * 1000) /* 60 s */
@@ -215,8 +218,6 @@
 	 */
 	if (mrq->done)
 		mrq->done(mrq);
-
-	/* mmc_crypto_debug(host); */
 }
 
 EXPORT_SYMBOL(mmc_request_done);
@@ -264,7 +265,7 @@
 	trace_mmc_request_start(host, mrq);
 
 	if (host->cqe_on)
-		host->cqe_ops->cqe_off(host);
+		host->cqe_ops->cqe_off(host, true);
 
 	host->ops->request(host, mrq);
 }
@@ -340,786 +341,6 @@
 	return 0;
 }
 
-#ifdef CONFIG_MTK_EMMC_CQ_SUPPORT
-static void mmc_enqueue_queue(struct mmc_host *host, struct mmc_request *mrq)
-{
-	unsigned long flags;
-
-	if (mrq->cmd->opcode == MMC_EXECUTE_READ_TASK ||
-		mrq->cmd->opcode == MMC_EXECUTE_WRITE_TASK) {
-
-		spin_lock_irqsave(&host->dat_que_lock, flags);
-		if (mrq->flags)
-			list_add(&mrq->link, &host->dat_que);
-		else
-			list_add_tail(&mrq->link, &host->dat_que);
-		spin_unlock_irqrestore(&host->dat_que_lock, flags);
-	} else {
-
-		spin_lock_irqsave(&host->cmd_que_lock, flags);
-		if (mrq->flags)
-			list_add(&mrq->link, &host->cmd_que);
-		else
-			list_add_tail(&mrq->link, &host->cmd_que);
-
-		spin_unlock_irqrestore(&host->cmd_que_lock, flags);
-
-	}
-}
-
-static void mmc_dequeue_queue(struct mmc_host *host, struct mmc_request *mrq)
-{
-	unsigned long flags;
-
-	if (mrq->cmd->opcode == MMC_EXECUTE_READ_TASK ||
-		mrq->cmd->opcode == MMC_EXECUTE_WRITE_TASK) {
-		spin_lock_irqsave(&host->dat_que_lock, flags);
-		list_del_init(&mrq->link);
-		spin_unlock_irqrestore(&host->dat_que_lock, flags);
-	}
-}
-
-static void mmc_clr_dat_mrq_que_flag(struct mmc_host *host)
-{
-	unsigned int i;
-
-	for (i = 0; i < host->card->ext_csd.cmdq_depth; i++)
-		host->data_mrq_queued[i] = false;
-}
-
-static void mmc_clr_dat_list(struct mmc_host *host)
-{
-
-	unsigned long flags;
-	struct mmc_request *mrq = NULL;
-	struct mmc_request *mrq_next = NULL;
-
-	spin_lock_irqsave(&host->dat_que_lock, flags);
-	list_for_each_entry_safe(mrq, mrq_next, &host->dat_que, link) {
-		list_del_init(&mrq->link);
-	}
-	spin_unlock_irqrestore(&host->dat_que_lock, flags);
-
-	mmc_clr_dat_mrq_que_flag(host);
-}
-
-static int mmc_restore_tasks(struct mmc_host *host)
-{
-	struct mmc_request *mrq_cmd = NULL;
-	unsigned int i = 0;
-	unsigned int task_id;
-	unsigned int tasks;
-
-	tasks = host->task_id_index;
-	for (task_id = 0; task_id < host->card->ext_csd.cmdq_depth; task_id++) {
-		if (tasks & 0x1) {
-			mrq_cmd = host->areq_que[task_id]->mrq_que;
-			mmc_enqueue_queue(host, mrq_cmd);
-			clear_bit(task_id, &host->task_id_index);
-			i++;
-		}
-		tasks >>= 1;
-	}
-
-	return i;
-}
-
-static struct mmc_request *mmc_get_cmd_que(struct mmc_host *host)
-{
-	struct mmc_request *mrq = NULL;
-
-	if (!list_empty(&host->cmd_que)) {
-		mrq = list_first_entry(&host->cmd_que,
-			struct mmc_request, link);
-		list_del_init(&mrq->link);
-	}
-
-	return mrq;
-}
-
-static struct mmc_request *mmc_get_dat_que(struct mmc_host *host)
-{
-	struct mmc_request *mrq = NULL;
-
-	if (!list_empty(&host->dat_que)) {
-		mrq = list_first_entry(&host->dat_que,
-			struct mmc_request, link);
-	}
-	return mrq;
-}
-
-static int mmc_blk_status_check(struct mmc_card *card, unsigned int *status)
-{
-	struct mmc_command cmd = {0};
-	int err, retries = 3;
-
-	cmd.opcode = MMC_SEND_STATUS;
-	cmd.arg = card->rca << 16;
-	cmd.flags = MMC_RSP_SPI_R2 | MMC_RSP_R1 | MMC_CMD_AC;
-	err = mmc_wait_for_cmd(card->host, &cmd, retries);
-	if (err == 0)
-		*status = cmd.resp[0];
-	else
-		pr_info("%s: err %d\n", __func__, err);
-
-	return err;
-}
-
-static void mmc_discard_cmdq(struct mmc_host *host)
-{
-	memset(&host->deq_cmd, 0, sizeof(struct mmc_command));
-	memset(&host->deq_mrq, 0, sizeof(struct mmc_request));
-
-	host->deq_cmd.opcode = MMC_CMDQ_TASK_MGMT;
-	host->deq_cmd.arg = 1;
-	host->deq_cmd.flags = MMC_RSP_SPI_R2 | MMC_RSP_R1B | MMC_CMD_AC;
-	host->deq_mrq.data = NULL;
-	host->deq_mrq.cmd = &host->deq_cmd;
-
-	host->deq_mrq.done = mmc_wait_cmdq_done;
-	host->deq_mrq.host = host;
-	host->deq_mrq.cmd->retries = 3;
-	host->deq_mrq.cmd->error = 0;
-	host->deq_mrq.cmd->mrq = &host->deq_mrq;
-
-	while (1) {
-		trace_mmc_request_start(host, &host->deq_mrq);
-		host->ops->request(host, &host->deq_mrq);
-
-		if (!host->deq_mrq.cmd->error ||
-			!host->deq_mrq.cmd->retries)
-			break;
-
-		pr_info("%s: req failed (CMD%u): %d, retrying...\n",
-			 __func__,
-			 host->deq_mrq.cmd->opcode,
-			 host->deq_mrq.cmd->error);
-
-		host->deq_mrq.cmd->retries--;
-		host->deq_mrq.cmd->error = 0;
-	};
-
-	pr_notice("%s: CMDQ send distard (CMD48)\n", __func__);
-}
-
-/* add for emmc reset when error happen */
-int emmc_resetting_when_cmdq;
-static int mmc_reset_for_cmdq(struct mmc_host *host)
-{
-	int err, ret;
-
-	emmc_resetting_when_cmdq = 1;
-	err = mmc_hw_reset(host);
-	/* Ensure we switch back to the correct partition */
-	if (err != -EOPNOTSUPP) {
-		u8 part_config = host->card->ext_csd.part_config;
-
-		part_config &= ~EXT_CSD_PART_CONFIG_ACC_MASK;
-		/*  only enable cq at user */
-		part_config |= 0;
-
-		ret = mmc_switch(host->card, EXT_CSD_CMD_SET_NORMAL,
-				EXT_CSD_PART_CONFIG, part_config,
-				host->card->ext_csd.part_time);
-		if (ret)
-			return ret;
-
-		/* enable cmdq at all partition */
-		ret = mmc_cmdq_enable(host->card);
-		if (ret)
-			return ret;
-
-		host->card->ext_csd.part_config = part_config;
-
-	}
-	emmc_resetting_when_cmdq = 0;
-	return err;
-}
-
-/*
- *	check CMDQ QSR
- */
-void mmc_do_check(struct mmc_host *host)
-{
-	memset(&host->que_cmd, 0, sizeof(struct mmc_command));
-	memset(&host->que_mrq, 0, sizeof(struct mmc_request));
-	host->que_cmd.opcode = MMC_SEND_STATUS;
-	host->que_cmd.arg = host->card->rca << 16 | 1 << 15;
-	host->que_cmd.flags = MMC_RSP_SPI_R2 | MMC_RSP_R1 | MMC_CMD_AC;
-	host->que_cmd.data = NULL;
-	host->que_mrq.cmd = &host->que_cmd;
-
-	host->que_mrq.done = mmc_wait_cmdq_done;
-	host->que_mrq.host = host;
-	host->que_mrq.cmd->retries = 3;
-	host->que_mrq.cmd->error = 0;
-	host->que_mrq.cmd->mrq = &host->que_mrq;
-	while (1) {
-		trace_mmc_request_start(host, &host->que_mrq);
-		host->ops->request(host, &host->que_mrq);
-
-		/* add for emmc reset when error happen */
-		if (host->que_mrq.cmd->error && !host->que_mrq.cmd->retries) {
-	/* wait data irq handle done otherwice timing issue will happen  */
-			msleep(2000);
-			if (mmc_reset_for_cmdq(host)) {
-				WARN_ON(1);
-				pr_info("%s: line=%d [CQ] reinit fail\n",
-					__func__, __LINE__);
-			}
-			mmc_clr_dat_list(host);
-			mmc_restore_tasks(host);
-			atomic_set(&host->cq_wait_rdy, 0);
-			atomic_set(&host->cq_rdy_cnt, 0);
-		}
-
-		if (!host->que_mrq.cmd->error ||
-			!host->que_mrq.cmd->retries)
-			break;
-
-		pr_info("%s: req failed (CMD%u): %d, retrying...\n",
-			 __func__,
-			 host->que_mrq.cmd->opcode,
-			 host->que_mrq.cmd->error);
-
-		host->que_mrq.cmd->retries--;
-		host->que_mrq.cmd->error = 0;
-	};
-}
-
-static void mmc_prep_chk_mrq(struct mmc_host *host)
-{
-	memset(&host->chk_cmd, 0, sizeof(struct mmc_command));
-	memset(&host->chk_mrq, 0, sizeof(struct mmc_request));
-	host->chk_cmd.opcode = MMC_SEND_STATUS;
-	host->chk_cmd.arg = host->card->rca << 16;
-	host->chk_cmd.flags = MMC_RSP_SPI_R2 | MMC_RSP_R1 | MMC_CMD_AC;
-	host->chk_cmd.data = NULL;
-	host->chk_mrq.cmd = &host->chk_cmd;
-
-	host->chk_mrq.done = mmc_wait_cmdq_done;
-	host->chk_mrq.host = host;
-	host->chk_mrq.cmd->error = 0;
-	host->chk_mrq.cmd->mrq = &host->chk_mrq;
-}
-
-static void mmc_prep_areq_que(struct mmc_host *host,
-	struct mmc_async_req *areq_que)
-{
-	areq_que->mrq->done = mmc_wait_cmdq_done;
-	areq_que->mrq->host = host;
-	areq_que->mrq->cmd->error = 0;
-	areq_que->mrq->cmd->mrq = areq_que->mrq;
-	areq_que->mrq->cmd->data =
-		areq_que->mrq->data;
-	areq_que->mrq->data->error = 0;
-	areq_que->mrq->data->mrq = areq_que->mrq;
-	if (areq_que->mrq->stop) {
-		areq_que->mrq->data->stop =
-			areq_que->mrq->stop;
-		areq_que->mrq->stop->error = 0;
-		areq_que->mrq->stop->mrq = areq_que->mrq;
-	}
-}
-
-/*
- *	check status register
- */
-void mmc_do_status(struct mmc_host *host)
-{
-	mmc_prep_chk_mrq(host);
-	trace_mmc_request_start(host, &host->chk_mrq);
-	host->ops->request(host, &host->chk_mrq);
-}
-
-/*
- * send stop command
- */
-void mmc_do_stop(struct mmc_host *host)
-{
-	memset(&host->que_cmd, 0, sizeof(struct mmc_command));
-	memset(&host->que_mrq, 0, sizeof(struct mmc_request));
-	host->que_cmd.opcode = MMC_STOP_TRANSMISSION;
-	host->que_cmd.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
-	host->que_mrq.cmd = &host->que_cmd;
-	host->que_mrq.done = mmc_wait_cmdq_done;
-	host->que_mrq.host = host;
-	host->que_mrq.cmd->retries = 3;
-	host->que_mrq.cmd->error = 0;
-	host->que_mrq.cmd->mrq = &host->que_mrq;
-
-	while (1) {
-		trace_mmc_request_start(host, &host->que_mrq);
-		host->ops->request(host, &host->que_mrq);
-
-		if (!host->que_mrq.cmd->error ||
-			!host->que_mrq.cmd->retries)
-			break;
-
-		pr_info("%s: req failed (CMD%u): %d, retrying...\n",
-			__func__,
-			host->que_mrq.cmd->opcode,
-			host->que_mrq.cmd->error);
-
-		host->que_mrq.cmd->retries--;
-		host->que_mrq.cmd->error = 0;
-	};
-}
-
-static int mmc_wait_tran(struct mmc_host *host)
-{
-	u32 status;
-	int err;
-	unsigned long timeout;
-
-	timeout = jiffies + msecs_to_jiffies(10 * 1000);
-	do {
-		err = mmc_blk_status_check(host->card, &status);
-		if (err) {
-			pr_notice("[CQ] check card status error = %d\n", err);
-			return 1;
-		}
-
-		if ((R1_CURRENT_STATE(status) == R1_STATE_DATA) ||
-			(R1_CURRENT_STATE(status) == R1_STATE_RCV))
-			mmc_do_stop(host);
-
-		if (time_after(jiffies, timeout)) {
-			pr_info("%s: Card stuck in %d state! %s\n",
-				mmc_hostname(host),
-				R1_CURRENT_STATE(status), __func__);
-			return 1;
-		}
-	} while (R1_CURRENT_STATE(status) != R1_STATE_TRAN);
-
-	return 0;
-}
-
-/*
- * check write
- */
-static int mmc_check_write(struct mmc_host *host, struct mmc_request *mrq)
-{
-	int ret = 0;
-	u32 status = 0;
-	struct mmc_queue_req *mq_rq;
-	struct mmc_async_req *areq_active;
-
-	if (mrq->cmd->opcode == MMC_EXECUTE_WRITE_TASK) {
-		ret = mmc_blk_status_check(host->card, &status);
-
-		if ((status & R1_WP_VIOLATION) || host->wp_error) {
-			mrq->data->error = -EROFS;
-			areq_active =
-				host->areq_que[(mrq->cmd->arg >> 16) & 0x1f];
-			mq_rq = container_of(areq_active, struct mmc_queue_req,
-					areq);
-			pr_notice(
-	"[%s]: data error = %d, status=0x%x, line:%d, block addr:0x%x\n",
-				__func__, mrq->data->error, status,
-				__LINE__, mq_rq->brq.que.arg);
-		}
-		mmc_wait_tran(host);
-		mrq->data->error = 0;
-		host->wp_error = 0;
-		atomic_set(&host->cq_w, false);
-	}
-
-	return ret;
-}
-
-unsigned long not_ready_time;
-void mmc_wait_cmdq_done(struct mmc_request *mrq)
-{
-	struct mmc_host *host = mrq->host;
-	struct mmc_command *cmd = mrq->cmd;
-	int done = 0, task_id;
-
-	if (cmd->opcode == MMC_SEND_STATUS ||
-		cmd->opcode == MMC_STOP_TRANSMISSION ||
-		cmd->opcode == MMC_CMDQ_TASK_MGMT) {
-		/* do nothing */
-	} else
-		mmc_dequeue_queue(host, mrq);
-
-	/* error - request done */
-	if (cmd->error) {
-		pr_info("%s: cmd%d arg:%x error:%d\n",
-			mmc_hostname(host),
-			cmd->opcode, cmd->arg,
-			cmd->error);
-		if ((cmd->opcode == MMC_EXECUTE_READ_TASK) ||
-			(cmd->opcode == MMC_EXECUTE_WRITE_TASK)) {
-			atomic_set(&host->cq_tuning_now, 1);
-			goto clear_end;
-		}
-		goto request_end;
-	}
-
-	/* data error */
-	if (mrq->data && mrq->data->error) {
-		pr_info("%s: cmd%d arg:%x data error:%d\n",
-			mmc_hostname(host),
-			cmd->opcode, cmd->arg,
-			mrq->data->error);
-		atomic_set(&host->cq_tuning_now, 1);
-		goto clear_end;
-	}
-
-	/* check wp violation */
-	if ((cmd->opcode == MMC_QUE_TASK_PARAMS) ||
-		(cmd->opcode == MMC_QUE_TASK_ADDR)) {
-
-		if (atomic_read(&host->cq_w)) {
-			if (cmd->resp[0] & R1_WP_VIOLATION)
-				host->wp_error = 1;
-		}
-	}
-
-	/* cmd13' - check queue ready & enqueue 46/47 */
-	if ((cmd->opcode == MMC_SEND_STATUS) && (cmd->arg & (1 << 15))) {
-		int i = 0;
-		unsigned int resp = cmd->resp[0];
-
-		if (resp == 0) {
-/* Workaround for ALPS03808823: if task not ready over 30s, reinit emmc */
-			if (!not_ready_time)
-				not_ready_time = jiffies;
-			else if (time_after(jiffies, not_ready_time
-			+ msecs_to_jiffies(30 * 1000))) {
-				pr_info("mmc0: error: task not ready over 30s\n");
-				msleep(2000);
-				if (mmc_reset_for_cmdq(host)) {
-					pr_info("%s: line=%d [CQ] reinit fail\n",
-						__func__, __LINE__);
-					WARN_ON(1);
-				}
-				mmc_clr_dat_list(host);
-				mmc_restore_tasks(host);
-				atomic_set(&host->cq_wait_rdy, 0);
-				atomic_set(&host->cq_rdy_cnt, 0);
-				not_ready_time = 0;
-
-				//aee_kernel_warning("mmc",
-				//	"task not ready over 30s");
-			}
-			goto request_end;
-		}
-		not_ready_time = 0;
-		do {
-			if ((resp & 1) && (!host->data_mrq_queued[i])) {
-				if (host->cur_rw_task == i) {
-					resp >>= 1;
-					i++;
-					continue;
-				}
-
-				if (!host->areq_que[i]) {
-					pr_info("%s: task %d not exist!,QSR:%x\n",
-						mmc_hostname(host), i,
-						cmd->resp[0]);
-					pr_info("%s: task_idx:%08lx\n",
-						mmc_hostname(host),
-						host->task_id_index);
-					pr_info("%s: cnt:%d,wait:%d,rdy:%d\n",
-						mmc_hostname(host),
-					mmc_hostname(host),
-					atomic_read(&host->areq_cnt),
-					atomic_read(&host->cq_wait_rdy),
-					atomic_read(&host->cq_rdy_cnt));
-					/* reset eMMC flow */
-					cmd->error = (unsigned int)-ETIMEDOUT;
-					cmd->retries = 0;
-					goto request_end;
-				}
-
-				atomic_dec(&host->cq_wait_rdy);
-				atomic_inc(&host->cq_rdy_cnt);
-
-				mmc_prep_areq_que(host, host->areq_que[i]);
-				mmc_enqueue_queue(host, host->areq_que[i]->mrq);
-				host->data_mrq_queued[i] = true;
-			}
-			resp >>= 1;
-			i++;
-		} while (resp && (i < host->card->ext_csd.cmdq_depth));
-	}
-
-	/* cmd46 - request done */
-	if (cmd->opcode == MMC_EXECUTE_READ_TASK
-		|| cmd->opcode == MMC_EXECUTE_WRITE_TASK)
-		goto clear_end;
-
-	goto request_end;
-
-clear_end:
-	task_id = ((cmd->arg >> 16) & 0x1f);
-	clear_bit(task_id, &host->task_id_index);
-	host->data_mrq_queued[task_id] = false;
-	done = 1;
-
-request_end:
-	/* request done when next data transfer */
-	if (done) {
-		WARN_ON(cmd->opcode != 46 && cmd->opcode != 47);
-		WARN_ON(host->done_mrq);
-		host->done_mrq = mrq;
-
-		/*
-		 * Need to wake up cmdq thread, after done rw.
-		 */
-		wake_up_interruptible(&host->cmdq_que);
-	}
-}
-
-static void mmc_wait_for_cmdq_done(struct mmc_host *host)
-{
-	while (atomic_read(&host->areq_cnt) != 0) {
-		wait_event_interruptible(host->cmp_que,
-			(atomic_read(&host->areq_cnt) == 0));
-	}
-}
-
-void mmc_wait_cmdq_empty(struct mmc_host *host)
-{
-	mmc_wait_for_cmdq_done(host);
-}
-
-#define CMD13_TMO_NS (1000 * 1000)
-int mmc_run_queue_thread(void *data)
-{
-	struct mmc_host *host = data;
-	struct mmc_request *cmd_mrq = NULL;
-	struct mmc_request *dat_mrq = NULL;
-	struct mmc_request *done_mrq = NULL;
-	unsigned int task_id, areq_cnt_chk, tmo;
-	bool is_done = false;
-	u32 status;
-	int err;
-	u64 chk_time = 0;
-    
-    struct sched_param scheduler_params = {0};
-
-	/* Set as RT priority */
-	scheduler_params.sched_priority = 1;
-	sched_setscheduler(current, SCHED_FIFO, &scheduler_params);
-
-	pr_info("[CQ] start cmdq thread\n");
-	mt_bio_queue_alloc(current, NULL, false);
-
-	while (1) {
-		mt_biolog_cmdq_check();
-		/* End request stage 1/2 */
-		if (atomic_read(&host->cq_rw)
-		|| (atomic_read(&host->areq_cnt) <= 1)) {
-			if (host->done_mrq) {
-				done_mrq = host->done_mrq;
-				host->done_mrq = NULL;
-			}
-		}
-
-		if (done_mrq) {
-			if (done_mrq->data->error || done_mrq->cmd->error) {
-				struct mmc_blk_request *brq = 
-					container_of(done_mrq, struct mmc_blk_request, mrq);
-
-				err = mmc_blk_status_check(host->card, &status);
-				if (err)
-					pr_debug("[CQ] check card status error = %d\n", err);
-				mmc_card_error_logging(host->card, brq, status);
-
-				mmc_wait_tran(host);
-				mmc_discard_cmdq(host);
-				mmc_wait_tran(host);
-				mmc_clr_dat_list(host);
-				atomic_set(&host->cq_rdy_cnt, 0);
-				if (host->ops->execute_tuning) {
-					err = host->ops->execute_tuning(host,
-				MMC_SEND_TUNING_BLOCK_HS200);
-					if (err && mmc_reset_for_cmdq(host)) {
-						pr_info("%s: line=%d ",
-							__func__, __LINE__);
-						pr_info("[CQ] reinit fail\n");
-						WARN_ON(1);
-					} else
-						pr_notice("[CQ] tuning pass\n");
-				}
-
-				host->cur_rw_task = CQ_TASK_IDLE;
-				task_id = (done_mrq->cmd->arg >> 16) & 0x1f;
-				trace_mmc_request_start(host,
-					host->areq_que[task_id]->mrq_que);
-				host->ops->request(host,
-					host->areq_que[task_id]->mrq_que);
-				atomic_set(&host->cq_wait_rdy, 1);
-				done_mrq = NULL;
-			}
-
-			atomic_set(&host->cq_rw, false);
-			if (done_mrq && !done_mrq->data->error
-			&& !done_mrq->cmd->error) {
-				task_id = (done_mrq->cmd->arg >> 16) & 0x1f;
-				mt_biolog_cmdq_dma_end(task_id);
-				mmc_check_write(host, done_mrq);
-				host->cur_rw_task = CQ_TASK_IDLE;
-				is_done = true;
-				mmc_complete_mqr_crypto(host);
-
-				if (atomic_read(&host->cq_tuning_now) == 1) {
-					mmc_restore_tasks(host);
-					atomic_set(&host->cq_tuning_now, 0);
-				}
-			}
-		}
-
-		/* Send Command 46/47 (DMA) */
-		if (!atomic_read(&host->cq_rw)) {
-			spin_lock_irq(&host->dat_que_lock);
-			dat_mrq = mmc_get_dat_que(host);
-
-			spin_unlock_irq(&host->dat_que_lock);
-
-			if (dat_mrq) {
-				WARN_ON(
-				dat_mrq->cmd->opcode !=
-				MMC_EXECUTE_WRITE_TASK
-				&& dat_mrq->cmd->opcode !=
-				MMC_EXECUTE_READ_TASK);
-
-				if (dat_mrq->cmd->opcode
-				== MMC_EXECUTE_WRITE_TASK)
-					atomic_set(&host->cq_w, true);
-
-				atomic_set(&host->cq_rw, true);
-				task_id = ((dat_mrq->cmd->arg >> 16) & 0x1f);
-				host->cur_rw_task = task_id;
-				trace_mmc_request_start(host, dat_mrq);
-				err = mmc_swcq_prepare_mqr_crypto(host,
-					dat_mrq);
-				if (err) {
-					pr_info("eMMC crypto fail %d\n", err);
-					WARN_ON(1);
-				}
-				host->ops->request(host, dat_mrq);
-				mt_biolog_cmdq_dma_start(task_id);
-				atomic_dec(&host->cq_rdy_cnt);
-				dat_mrq = NULL;
-			}
-		}
-
-		/* End request stage 2/2 */
-		if (is_done) {
-			task_id = (done_mrq->cmd->arg >> 16) & 0x1f;
-			mt_biolog_cmdq_isdone_start(task_id,
-				host->areq_que[task_id]->mrq_que);
-			mt_biolog_cmdq_isdone_end(task_id);
-			mt_biolog_cmdq_check();
-			mmc_blk_end_queued_req(host, done_mrq->areq, task_id);
-			done_mrq = NULL;
-			is_done = false;
-		}
-
-		/* Send Command 44/45 */
-		if (atomic_read(&host->cq_tuning_now) == 0) {
-
-			spin_lock_irq(&host->cmd_que_lock);
-			cmd_mrq = mmc_get_cmd_que(host);
-			spin_unlock_irq(&host->cmd_que_lock);
-
-			while (cmd_mrq) {
-				task_id = ((cmd_mrq->sbc->arg >> 16) & 0x1f);
-				mt_biolog_cmdq_queue_task(task_id, cmd_mrq);
-				if (host->task_id_index & (1 << task_id)) {
-					pr_info(
-"[%s] BUG!!! task_id %d used, task_id_index 0x%08lx, areq_cnt = %d, cq_wait_rdy = %d\n",
-					__func__, task_id, host->task_id_index,
-					atomic_read(&host->areq_cnt),
-					atomic_read(&host->cq_wait_rdy));
-					/* mmc_cmd_dump(host); */
-					while (1)
-						;
-				}
-				set_bit(task_id, &host->task_id_index);
-				trace_mmc_request_start(host, cmd_mrq);
-				host->ops->request(host, cmd_mrq);
-				/* add for emmc reset when error happen */
-				if ((cmd_mrq->sbc && cmd_mrq->sbc->error)
-				|| cmd_mrq->cmd->error) {
-		/* wait data irq handle done otherwise timing issue happen*/
-					msleep(2000);
-					if (mmc_reset_for_cmdq(host)) {
-						pr_info("%s: line=%d ",
-							__func__, __LINE__);
-						pr_info("[CQ] reinit fail\n");
-						WARN_ON(1);
-					}
-					mmc_clr_dat_list(host);
-					mmc_restore_tasks(host);
-					atomic_set(&host->cq_wait_rdy, 0);
-					atomic_set(&host->cq_rdy_cnt, 0);
-				} else
-					atomic_inc(&host->cq_wait_rdy);
-
-				spin_lock_irq(&host->cmd_que_lock);
-				cmd_mrq = mmc_get_cmd_que(host);
-				spin_unlock_irq(&host->cmd_que_lock);
-			}
-		}
-		if (atomic_read(&host->cq_rw)) {
-			/* wait for event to wakeup */
-			/* wake up when new request arrived and dma done */
-			areq_cnt_chk = atomic_read(&host->areq_cnt);
-			tmo = wait_event_interruptible_timeout(host->cmdq_que,
-				host->done_mrq ||
-				(atomic_read(&host->areq_cnt) > areq_cnt_chk),
-				10 * HZ);
-			if (!tmo) {
-				pr_info("%s:tmo,mrq(%p),chk(%d),cnt(%d)\n",
-					__func__,
-					host->done_mrq,
-					areq_cnt_chk,
-					atomic_read(&host->areq_cnt));
-				pr_info("%s:tmo,rw(%d),wait(%d),rdy(%d)\n",
-					__func__,
-					atomic_read(&host->cq_rw),
-					atomic_read(&host->cq_wait_rdy),
-					atomic_read(&host->cq_rdy_cnt));
-			}
-			/* DMA time should not count in polling time */
-			chk_time = 0;
-		}
-		/* Send Command 13' */
-
-		if (atomic_read(&host->cq_wait_rdy) > 0
-			&& atomic_read(&host->cq_rdy_cnt) == 0) {
-			if (!chk_time)
-				/* set check time */
-				chk_time = sched_clock();
-
-			/* send cmd13' */
-			mmc_do_check(host);
-
-			if (atomic_read(&host->cq_rdy_cnt))
-				/* clear when got ready task */
-				chk_time = 0;
-			else if (sched_clock() - chk_time > CMD13_TMO_NS)
-				/* sleep when TMO */
-				usleep_range(2000, 5000);
-		}
-
-		/* Sleep when nothing to do */
-		mt_biolog_cmdq_check();
-		set_current_state(TASK_INTERRUPTIBLE);
-		if (atomic_read(&host->areq_cnt) == 0)
-			schedule();
-
-		set_current_state(TASK_RUNNING);
-	}
-	mt_bio_queue_free(current);
-	return 0;
-}
-#endif
-
 int mmc_start_request(struct mmc_host *host, struct mmc_request *mrq)
 {
 	int err;
@@ -1138,24 +359,7 @@
 	err = mmc_mrq_prep(host, mrq);
 	if (err)
 		return err;
-#ifdef CONFIG_MTK_EMMC_CQ_SUPPORT
-	if (mrq->done == mmc_wait_cmdq_done) {
-		mmc_enqueue_queue(host, mrq);
-		wake_up_process(host->cmdq_thread);
-		led_trigger_event(host->led, LED_FULL);
-		return 0;
-	}
-	if (host->card
-		&& host->card->ext_csd.cmdq_support
-		&& mrq->cmd->opcode != MMC_SEND_STATUS)
-		/* add for emmc reset when error happen */
-		/* cannot wait cmdq empty for init requests
-		 * when emmc resetting when cmdq
-		 */
-		if (strncmp(current->comm, "exe_cq", 6)
-			|| !emmc_resetting_when_cmdq)
-			mmc_wait_cmdq_empty(host);
-#endif
+
 	led_trigger_event(host->led, LED_FULL);
 	__mmc_start_request(host, mrq);
 
@@ -1375,6 +579,8 @@
 	cmd.busy_timeout = MMC_CQE_RECOVERY_TIMEOUT,
 	mmc_wait_for_cmd(host, &cmd, 0);
 
+	mmc_card_error_logging(host->card, NULL, cmd.resp[0]);
+
 	memset(&cmd, 0, sizeof(cmd));
 	cmd.opcode       = MMC_CMDQ_TASK_MGMT;
 	cmd.arg          = 1; /* Discard entire queue */
@@ -1382,7 +588,12 @@
 	cmd.flags       &= ~MMC_RSP_CRC; /* Ignore CRC */
 	cmd.busy_timeout = MMC_CQE_RECOVERY_TIMEOUT,
 	err = mmc_wait_for_cmd(host, &cmd, 0);
+	if (err)
+		pr_warn("%s: Fail TASK MGMT in CQE recovery: %d\n", mmc_hostname(host),err);
 
+	err = mmc_hw_reset(host);
+	if (err)
+		pr_warn("%s: Fail reset in CQE recovery: %d\n", mmc_hostname(host),err);
 	host->cqe_ops->cqe_recovery_finish(host);
 
 	mmc_retune_release(host);
@@ -1424,8 +635,10 @@
 void mmc_wait_for_req(struct mmc_host *host, struct mmc_request *mrq)
 {
 #ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
-	if (mmc_bus_needs_resume(host))
+	if (mmc_bus_needs_resume(host)) {
+		host->bus_resume_flags |= MMC_BUSRESUME_ENTER_CMD;
 		mmc_resume_bus(host);
+	}
 #endif
 	__mmc_start_req(host, mrq);
 
@@ -1671,6 +884,45 @@
 EXPORT_SYMBOL(__mmc_claim_host);
 
 /**
+ *     mmc_try_claim_host - try exclusively to claim a host
+ *        and keep trying for given time, with a gap of 10ms
+ *     @host: mmc host to claim
+ *     @dealy_ms: delay in ms
+ *
+ *     Returns %1 if the host is claimed, %0 otherwise.
+ */
+int __mmc_try_claim_host(struct mmc_host *host, struct mmc_ctx *ctx,
+			unsigned int delay_ms)
+{
+	struct task_struct *task = ctx ? NULL : current;
+	int claimed_host = 0;
+	unsigned long flags;
+	int retry_cnt = delay_ms/10;
+	bool pm = false;
+
+	do {
+		spin_lock_irqsave(&host->lock, flags);
+		if (!host->claimed || mmc_ctx_matches(host, ctx, task)) {
+			host->claimed = 1;
+			mmc_ctx_set_claimer(host, ctx, task);
+			host->claim_cnt += 1;
+			claimed_host = 1;
+			if (host->claim_cnt == 1)
+				pm = true;
+		}
+		spin_unlock_irqrestore(&host->lock, flags);
+		if (!claimed_host)
+			mmc_delay(10);
+	} while (!claimed_host && retry_cnt--);
+
+	if (pm)
+		pm_runtime_get_sync(mmc_dev(host));
+
+	return claimed_host;
+}
+EXPORT_SYMBOL(__mmc_try_claim_host);
+
+/**
  *	mmc_release_host - release a host
  *	@host: mmc host to release
  *
@@ -1707,10 +959,6 @@
 {
 	pm_runtime_get_sync(&card->dev);
 	__mmc_claim_host(card->host, ctx, NULL);
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
-	if (mmc_bus_needs_resume(card->host))
-		mmc_resume_bus(card->host);
-#endif
 }
 EXPORT_SYMBOL(mmc_get_card);
 
@@ -1781,7 +1029,7 @@
 		return 0;
 
 	if (host->cqe_on)
-		host->cqe_ops->cqe_off(host);
+		host->cqe_ops->cqe_off(host, true);
 
 	if (mmc_card_mmc(card))
 		opcode = MMC_SEND_TUNING_BLOCK_HS200;
@@ -1823,7 +1071,7 @@
 void mmc_set_initial_state(struct mmc_host *host)
 {
 	if (host->cqe_on)
-		host->cqe_ops->cqe_off(host);
+		host->cqe_ops->cqe_off(host, true);
 
 	mmc_retune_disable(host);
 
@@ -2346,8 +1594,10 @@
 	cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
 
 	err = mmc_wait_for_cmd(host, &cmd, 0);
-	if (err)
-		return err;
+	if (err) {
+		err = -EAGAIN;
+		goto power_cycle;
+	}
 
 	if (!mmc_host_is_spi(host) && (cmd.resp[0] & R1_ERROR))
 		return -EIO;
@@ -2554,37 +1804,43 @@
 	spin_unlock_irqrestore(&host->lock, flags);
 }
 
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 int mmc_resume_bus(struct mmc_host *host)
 {
 	unsigned long flags;
+	int err = 0;
 
 	if (!mmc_bus_needs_resume(host))
 		return -EINVAL;
 
-	pr_notice("%s: Starting deferred resume\n", mmc_hostname(host));
-
-	__pm_stay_awake(host->detect_wake_lock);
-
+	pr_info("%s: Starting deferred resume\n", mmc_hostname(host));
+	wake_lock(&host->detect_wake_lock);
 	spin_lock_irqsave(&host->lock, flags);
 	host->bus_resume_flags &= ~MMC_BUSRESUME_NEEDS_RESUME;
 	host->rescan_disable = 0;
 	spin_unlock_irqrestore(&host->lock, flags);
 
+	/* Host restor */
+	host->ops->restore_host(host);
+
 	mmc_bus_get(host);
-	if (host->bus_ops && !host->bus_dead && host->card) {
+	if (host->bus_ops && !host->bus_dead) {
 		mmc_power_up(host, host->card->ocr);
-		WARN_ON(!host->bus_ops->resume);
-		host->bus_ops->resume(host);
+		BUG_ON(!host->bus_ops->resume);
+		err = host->bus_ops->resume(host);
 	}
 
 	mmc_bus_put(host);
-	pr_notice("%s: Deferred resume completed\n", mmc_hostname(host));
-	__pm_relax(host->detect_wake_lock);
+
+	spin_lock_irqsave(&host->lock, flags);
+	host->bus_resume_flags &=
+		~(MMC_BUSRESUME_ENTER_IO | MMC_BUSRESUME_ENTER_CMD);
+	spin_unlock_irqrestore(&host->lock, flags);
+	wake_unlock(&host->detect_wake_lock);
+	pr_info("%s: Deferred resume completed, err : %d\n", mmc_hostname(host), err);
 	return 0;
 }
+
 EXPORT_SYMBOL(mmc_resume_bus);
-#endif
 
 /*
  * Assign a mmc bus handler to a host. Only one bus handler may control a
@@ -2639,11 +1895,9 @@
 		pm_wakeup_event(mmc_dev(host), 5000);
 
 	host->detect_change = 1;
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
-	/* wake lock : 500ms */
+	/* wake lock: 500ms */
 	if (!(host->caps & MMC_CAP_NONREMOVABLE))
-		__pm_wakeup_event(host->detect_wake_lock, HZ / 2);
-#endif
+		wake_lock_timeout(&host->detect_wake_lock, HZ / 2);
 	mmc_schedule_delayed_work(&host->detect, delay);
 }
 
@@ -2890,11 +2144,8 @@
 	 * the erase operation does not exceed the max_busy_timeout, we should
 	 * use R1B response. Or we need to prevent the host from doing hw busy
 	 * detection, which is done by converting to a R1 response instead.
-	 * Note, some hosts requires R1B, which also means they are on their own
-	 * when it comes to deal with the busy timeout.
 	 */
-	if (!(card->host->caps & MMC_CAP_NEED_RSP_BUSY) &&
-	    card->host->max_busy_timeout &&
+	if (card->host->max_busy_timeout &&
 	    busy_timeout > card->host->max_busy_timeout) {
 		cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_AC;
 	} else {
@@ -3109,11 +2360,15 @@
 
 int mmc_can_sanitize(struct mmc_card *card)
 {
+#ifdef CONFIG_MMC_SANITIZE
 	if (!mmc_can_trim(card) && !mmc_can_erase(card))
 		return 0;
 	if (card->ext_csd.sec_feature_support & EXT_CSD_SEC_SANITIZE)
 		return 1;
+#else
+	/* Do Not use Sanitize */
 	return 0;
+#endif /* CONFIG_MMC_SANITIZE */
 }
 EXPORT_SYMBOL(mmc_can_sanitize);
 
@@ -3220,6 +2475,9 @@
 	struct mmc_host *host = card->host;
 	unsigned int max_discard, max_trim;
 
+	if (!host->max_busy_timeout)
+		return UINT_MAX;
+
 	/*
 	 * Without erase_group_def set, MMC erase timeout depends on clock
 	 * frequence which can change.  In that case, the best choice is
@@ -3400,12 +2658,12 @@
 	 */
 	if (!ret && host->ops->get_cd && !host->ops->get_cd(host)) {
 		mmc_detect_change(host, msecs_to_jiffies(200));
-		pr_debug("%s: card removed too slowly\n", mmc_hostname(host));
+		pr_err("%s: card removed too slowly\n", mmc_hostname(host));
 	}
 
 	if (ret) {
 		mmc_card_set_removed(host->card);
-		pr_debug("%s: card remove detected\n", mmc_hostname(host));
+		pr_err("%s: card remove detected\n", mmc_hostname(host));
 		ST_LOG("<%s> %s: card remove detected\n", __func__, mmc_hostname(host));
 	}
 
@@ -3452,32 +2710,38 @@
 
 void mmc_rescan(struct work_struct *work)
 {
-	unsigned long flags;
 	struct mmc_host *host =
 		container_of(work, struct mmc_host, detect.work);
 	int i;
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 	bool extend_wakelock = false;
-#endif
-	spin_lock_irqsave(&host->lock, flags);
-	if (host->rescan_disable) {
-		spin_unlock_irqrestore(&host->lock, flags);
+
+	if (host->rescan_disable)
+		return;
+
+	/* check if hw interrupt is triggered */
+	if (!host->trigger_card_event && !host->card) {
+		pr_err("%s: no detect irq, skipping mmc_rescan\n", mmc_hostname(host));
+		if (wake_lock_active(&host->detect_wake_lock))
+			wake_unlock(&host->detect_wake_lock);
 		return;
 	}
-	spin_unlock_irqrestore(&host->lock, flags);
 
 	/* If there is a non-removable card registered, only scan once */
 	if (!mmc_card_is_removable(host) && host->rescan_entered)
 		return;
 	host->rescan_entered = 1;
 
+	/* runtime_pm enable */
+	host->ops->runtime_pm_control(host, 1);
+
 	if (host->trigger_card_event && host->ops->card_event) {
 		mmc_claim_host(host);
 		host->ops->card_event(host);
 		mmc_release_host(host);
-		host->trigger_card_event = false;
 	}
 
+	host->trigger_card_event = false;
+
 	mmc_bus_get(host);
 
 	/*
@@ -3513,28 +2777,32 @@
 			host->ops->get_cd(host) == 0) {
 		mmc_power_off(host);
 		mmc_release_host(host);
+		/* runtime_pm disable */
+		host->ops->runtime_pm_control(host, 0);
 		goto out;
+	} else {
+		/* runtime_pm disable */
+		host->ops->runtime_pm_control(host, 1);
 	}
 
 	for (i = 0; i < ARRAY_SIZE(freqs); i++) {
 		if (!mmc_rescan_try_freq(host, max(freqs[i], host->f_min))) {
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 			extend_wakelock = true;
-#endif
 			break;
 		}
+
 		if (freqs[i] <= host->f_min)
 			break;
 	}
 	mmc_release_host(host);
-
+	/* runtime_pm disable */
+	host->ops->runtime_pm_control(host, 0);
  out:
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 	if (extend_wakelock && !host->rescan_disable)
-		__pm_wakeup_event(host->detect_wake_lock, HZ / 2);
-	else if (host->detect_wake_lock->active)
-		__pm_relax(host->detect_wake_lock);
-#endif
+		wake_lock_timeout(&host->detect_wake_lock, HZ / 2);
+	else if (wake_lock_active(&host->detect_wake_lock))
+		wake_unlock(&host->detect_wake_lock);
+
 	if (host->caps & MMC_CAP_NEEDS_POLL)
 		mmc_schedule_delayed_work(&host->detect, HZ);
 }
@@ -3545,14 +2813,33 @@
 	host->rescan_disable = 0;
 	host->ios.power_mode = MMC_POWER_UNDEFINED;
 
-	if (!(host->caps2 & MMC_CAP2_NO_PRESCAN_POWERUP)) {
-		mmc_claim_host(host);
-		mmc_power_up(host, host->ocr_avail);
-		mmc_release_host(host);
-	}
+	if (host->caps2 & MMC_CAP2_SKIP_INIT_NOT_TRAY) {
+		if (host->ops->get_cd && host->ops->get_cd(host)) {
+			pr_info("SD tray detect\n");
+			if (!(host->caps2 & MMC_CAP2_NO_PRESCAN_POWERUP)) {
+				mmc_claim_host(host);
+				mmc_power_up(host, host->ocr_avail);
+				mmc_release_host(host);
+			}
 
-	mmc_gpiod_request_cd_irq(host);
-	_mmc_detect_change(host, 0, false);
+			mmc_gpiod_request_cd_irq(host);
+			_mmc_detect_change(host, 0, false);
+		} else
+			pr_info("SD tray not detect\n");
+	} else {
+		if (!(host->caps2 & MMC_CAP2_NO_PRESCAN_POWERUP)) {
+			mmc_claim_host(host);
+			mmc_power_up(host, host->ocr_avail);
+			mmc_release_host(host);
+		}
+
+		if (host->caps2 & MMC_CAP2_SKIP_INIT_SCAN)
+			pr_debug("%s skip mmc detect change\n", mmc_hostname(host));
+		else {
+			mmc_gpiod_request_cd_irq(host);
+			_mmc_detect_change(host, 0, false);
+		}
+	}
 }
 
 void mmc_stop_host(struct mmc_host *host)
@@ -3568,7 +2855,6 @@
 	/* clear pm flags now and let card drivers set them as needed */
 	host->pm_flags = 0;
 
-
 	mmc_bus_get(host);
 	if (host->bus_ops && !host->bus_dead) {
 		/* Calling bus_ops->remove() with a claimed host can deadlock */
@@ -3605,21 +2891,22 @@
 	case PM_SUSPEND_PREPARE:
 	case PM_RESTORE_PREPARE:
 		spin_lock_irqsave(&host->lock, flags);
+		if (mmc_bus_needs_resume(host)) {
+			spin_unlock_irqrestore(&host->lock, flags);
+			break;
+		}
 		host->rescan_disable = 1;
 		spin_unlock_irqrestore(&host->lock, flags);
 		cancel_delayed_work_sync(&host->detect);
 
 		if (!host->bus_ops)
 			break;
-
-#ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 		/*
-		 * It is possible that the wake-lock has been acquired, since
-		 * its being suspended, release the wakelock
+	         * It is possible that the wake-lock has been acquired, since
 		 */
-		if (host->detect_wake_lock->active)
-			__pm_relax(host->detect_wake_lock);
-#endif
+		if (wake_lock_active(&host->detect_wake_lock))
+			wake_unlock(&host->detect_wake_lock);
+
 		/* Validate prerequisites for suspend */
 		if (host->bus_ops->pre_suspend)
 			err = host->bus_ops->pre_suspend(host);
@@ -3646,6 +2933,7 @@
 	case PM_POST_SUSPEND:
 	case PM_POST_HIBERNATION:
 	case PM_POST_RESTORE:
+
 		spin_lock_irqsave(&host->lock, flags);
 		host->rescan_disable = 0;
 		spin_unlock_irqrestore(&host->lock, flags);
